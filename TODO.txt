
* Pixel-by-pixel recognition is not good enough. We need to do a recursive bisection, starting off with the character -- find COM and intensity of the whole thing. Then split into 4 pieces, and calculate this as well, and continue until we reach a single pizel. Store them all. 


* Figure out why extended Ascii chars look worse than normal... this shouldn't be!


* Compare to characters which are less than 100% gray, so that <50% intensity does not prefer matching to blank space
* Investigate input charmap and input image color normalization.


* Don't crash if intensity_weight is 0 or 1.


* Make box size optional... handle arbitrary-sized images
* Be able to set the desired width






* Eliminate rendering completely. Instead, provide a text file of every unicode character that has ever existed, and then take thousands of screenshots in order to capture them all, crop them perfectly, manually, and then provide this as input to the program for analysis.
